# Scripts Used in the Testing Phase

## **Project Overview**  
This repository contains the scripts and notebooks used during the **Testing Phase** of the text classification project based on Large Language Models (LLMs). The primary objective of the project is to evaluate and categorize texts according to their suitability for audiences under 15 years old, using predefined criteria and various configurations of prompts and models.

---

## **Repository Contents**  
The repository is organized into folders representing different stages and configurations of the tests:

1. **`Testing_Data.ipynb`:**  
   Defines the **15 sample texts** and a simple prompt used to generate initial responses with the four selected models. The results were stored in a JSON file for later analysis.

2. **`Expected_Outcome_Updated.ipynb`:**  
   This file includes the code to iterate over the texts and calculate the **mode of the responses** generated by the models. This mode was used as the **expected output**, serving as the benchmark to evaluate the consistency of the models' responses.

3. **`Testing_Updated.ipynb`:**  
   Implements the final tests using the **three additional prompts** (simple, chain of thought, and detailed). This notebook also includes an automated loop to evaluate all possible combinations of models, prompts, and texts.

4. **`Analysis_Updated.ipynb`:**  
   Contains the scripts to calculate evaluation metrics, including **accuracy**, **F1-score**, **precision**, and **recall**, comparing the generated responses to the previously defined expected output.

---

## **How to Use This Repository**  
### **Prerequisites:**
- Python 3.8 or higher.
- Required libraries: `pandas`, `numpy`, `matplotlib`, `scikit-learn`, and `openai`.

### **Steps to Execute:**
1. Run the `Testing_Data.ipynb` file first to generate the initial dataset of responses.
2. Use `Expected_Outcome_Updated.ipynb` to calculate the expected output.
3. Execute `Testing_Updated.ipynb` to evaluate the responses generated under different configurations of prompts and models.
4. Finally, use `Analysis_Updated.ipynb` to analyze the results and compute evaluation metrics.

### **Important Note:**
- Ensure you correctly load your OpenAI credentials before running scripts that interact with models like GPT-4o or GPT-4-mini.
- This repository is configured for research and testing purposes. It is not recommended for production environments without additional adjustments.

---

## **Purpose of the Repository**  
This repository aims to provide transparency in the methods and processes used during the project's testing phase. The included scripts are fundamental for reproducing the obtained results and validating the conclusions presented in the final project report.

---
